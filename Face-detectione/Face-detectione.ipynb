{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c86509e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'dara2.jpg'\n",
    "face_cascade = \"haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "77ca4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ca755aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(face_cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "941eb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_image = cv2.imread(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "dc054e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(cover_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8eac4b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_classifier.detectMultiScale(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b5cd1106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[189, 103, 191, 191],\n",
       "       [196, 406,  53,  53]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b47d3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cdab54a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[102, 110, 103],\n",
       "        [101, 109, 102],\n",
       "        [101, 109, 102],\n",
       "        ...,\n",
       "        [ 75,  87,  93],\n",
       "        [101, 113, 123],\n",
       "        [117, 132, 141]],\n",
       "\n",
       "       [[103, 111, 104],\n",
       "        [102, 110, 103],\n",
       "        [102, 110, 103],\n",
       "        ...,\n",
       "        [ 70,  83,  91],\n",
       "        [100, 116, 128],\n",
       "        [120, 136, 148]],\n",
       "\n",
       "       [[103, 114, 106],\n",
       "        [102, 113, 105],\n",
       "        [102, 113, 105],\n",
       "        ...,\n",
       "        [ 80,  98, 109],\n",
       "        [112, 131, 146],\n",
       "        [130, 151, 166]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 17,  11,   6],\n",
       "        [ 17,  11,   6],\n",
       "        [ 17,  11,   6],\n",
       "        ...,\n",
       "        [175, 191, 228],\n",
       "        [171, 186, 225],\n",
       "        [169, 184, 223]],\n",
       "\n",
       "       [[ 17,  11,   6],\n",
       "        [ 17,  11,   6],\n",
       "        [ 17,  11,   6],\n",
       "        ...,\n",
       "        [169, 185, 222],\n",
       "        [165, 180, 219],\n",
       "        [162, 177, 216]],\n",
       "\n",
       "       [[ 17,  11,   6],\n",
       "        [ 17,  11,   6],\n",
       "        [ 17,  11,   6],\n",
       "        ...,\n",
       "        [167, 183, 220],\n",
       "        [162, 177, 216],\n",
       "        [158, 173, 212]]], dtype=uint8)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.rectangle(cover_image, (x, y), (x+w, y+h), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "acb9a584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Result\", cover_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "296ffcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = r'vong.jpg'\n",
    "face_cascade = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(face_cascade)\n",
    "cover_image = cv2.imread(image)\n",
    "gray = cv2.cvtColor(cover_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray)\n",
    "for face in faces:\n",
    "    x, y, w, h = faces[0]\n",
    "    cv2.rectangle(cover_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Result\", cover_image)\n",
    "cv2.waitKey(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1529b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
